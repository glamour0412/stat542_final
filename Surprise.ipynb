{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnHw9fBj7U7p",
        "outputId": "9feb8455-bddf-4f21-b7a1-769dedea9ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.10.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp39-cp39-linux_x86_64.whl size=3195784 sha256=f2230aac402dd397d6f9cbdef6cfa0544f11f55a2cacea193ac9022f9da05b12\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/3a/46/9b17b3512bdf283c6cb84f59929cdd5199d4e754d596d22784\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import SVD\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/df_c_1.csv', index_col=0)\n",
        "\n",
        "# Create a reader and specify the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset into the surprise format\n",
        "data = Dataset.load_from_df(df.stack().reset_index().rename(columns={0: 'rating', 'level_0': 'user_id', 'level_1': 'item_id'}), reader)\n",
        "\n",
        "# Split the data into 50% train and 50% test\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# Apply the SVD algorithm on the training set\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testing set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate the RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error: \", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg-dInD4OcWI",
        "outputId": "821792bc-802a-4ada-bb64-6e0c5aaff04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7994\n",
            "Root Mean Squared Error:  0.7994184744758015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import SVDpp\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/df_c_0.1.csv', index_col=0)\n",
        "\n",
        "# Create a reader and specify the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset into the surprise format\n",
        "data = Dataset.load_from_df(df.stack().reset_index().rename(columns={0: 'rating', 'level_0': 'user_id', 'level_1': 'item_id'}), reader)\n",
        "\n",
        "# Split the data into 50% train and 50% test\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# Apply the SVD algorithm on the training set\n",
        "algo = SVDpp(cache_ratings=False)\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testing set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate the RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error: \", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0id4HRzhSkiw",
        "outputId": "5a7fe673-c3de-4341-a25d-34d8ce13b396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.6866\n",
            "Root Mean Squared Error:  0.6865513271939643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import NMF\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/df_fill3.csv', index_col=0)\n",
        "\n",
        "# Create a reader and specify the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset into the surprise format\n",
        "data = Dataset.load_from_df(df.stack().reset_index().rename(columns={0: 'rating', 'level_0': 'user_id', 'level_1': 'item_id'}), reader)\n",
        "\n",
        "# Split the data into 50% train and 50% test\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# Apply the NMF algorithm on the training set\n",
        "algo = NMF()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testing set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate the RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error: \", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJJ2-AD2XhMQ",
        "outputId": "8eebe8e3-fe0c-4bba-cd0e-863b6d68ef56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7758\n",
            "Root Mean Squared Error:  0.7757894766539731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UpKqrXbuvwt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import KNNBasic\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/df_fill3.csv', index_col=0)\n",
        "\n",
        "# Create a reader and specify the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset into the surprise format\n",
        "data = Dataset.load_from_df(df.stack().reset_index().rename(columns={0: 'rating', 'level_0': 'user_id', 'level_1': 'item_id'}), reader)\n",
        "\n",
        "# Split the data into 50% train and 50% test\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# Apply the SVD algorithm on the training set\n",
        "algo = KNNBasic()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testing set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate the RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error: \", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbT-BhiMwF-w",
        "outputId": "6c682941-7419-42d8-9b16-c7dc18fbb0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.7862\n",
            "Root Mean Squared Error:  0.7861587325890065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy, Dataset, SVD, SVDpp\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin(\"ml-100k\")\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 50% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVDpp(cache_ratings=False)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "LJgk1564ywVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy, Dataset, NMF\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed)\n",
        "data = Dataset.load_builtin(\"ml-1m\")\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 50% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# We'll use the NMF algorithm.\n",
        "algo = NMF(n_factors=50, biased=False)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)\n"
      ],
      "metadata": {
        "id": "JqxmRU2_yy5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy, Dataset, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed)\n",
        "data = Dataset.load_builtin(\"ml-100k\")\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 50% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=0.5)\n",
        "\n",
        "# We'll use the NMF algorithm.\n",
        "algo = KNNBasic()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAaKgs00y0pD",
        "outputId": "4756070b-877e-4ec2-f620-08f51649e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0030012160481088"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpfWhbwKxajN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbIhyPa1xcma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}